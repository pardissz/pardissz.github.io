<html class="no-js" lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Pardis Sadat Zahraei</title>
   <link rel="shortcut icon" href="favicon2.ico" type="image/x-icon">
   <link rel="icon" href="favicon2.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    <link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
</head>

<body>
    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            <li>
                <a href="#about">About</a>
            </li>
            <li>
                <a href="#publications">Publications</a>
            </li>
            <li>
                <a href="#projects">Projects</a>
            </li>
            <li>
                <a href="#contact">Contact</a>
            </li>
        </ul>
    </header>
    <div id="lead">
        <div id="lead-content">
            <h1>Pardis Sadat Zahraei</h1>
            <h2>PhD Student in Computer Science</h2>
            <a href="resume.pdf" class="btn-rounded-white" download="Resume.pdf">Download Resume</a>
        </div>
        <div id="lead-overlay"></div>

        <div id="lead-down">
            <span>
                <i class="fa fa-chevron-down" aria-hidden="true"></i>
            </span>
        </div>
        </div>
    <div id="about">
    <div class="container">

        <div class="row">
            <div class="col-md-4">
                <h2 class="heading">About Me</h2>
                <img src="images/person.jpg" alt="Your Name" class="profile-picture">
            </div>
            <div class="col-md-8">
                <div class="about-text">
                    <p>
I am a first-year PhD student in Computer Science at the University of Illinois at Urbana-Champaign (UIUC). My research focuses on Natural Language Processing (NLP), with a particular interest in the safety and alignment of large language models (LLMs). I develop methods and benchmarks to evaluate and enhance LLMs in areas such as multilingual and cross-cultural understanding, reasoning, and ethics. You can also find me active on <a href="https://x.com/PardisZahraei" target="_blank">X (Twitter)</a>.
                      </p>
                </div>
            </div>
        </div>
    </div>
</div>
    <div id="publications" class="background-alt">
        <h2 class="heading">Publications</h2>
        <div class="container">
            <div class="row">
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="Your paragraph text (9) (1).png" />
                    </div>
                    <div class="project-info">
                        <h3 style="color: #FF6347;"><B>MENA Values Benchmark for Evaluating Cultural Alignment and Multilingual Bias in LLMs</B> (Under Review - NeurIPS 2025)</h3>
                        <h4><span style="text-decoration: underline;">Pardis Sadat Zahraei</span>, Ehsaneddin Asgari</h4>
                        <p>
We introduce MENAValues, a new benchmark to evaluate how LLMs align with the cultural values of the Middle East and North Africa. Our research reveals that LLM responses are sensitive to language and framing, with models showing shifts in cultural alignment and, in some cases, producing biased outputs. We also identify a phenomenon called "Logit Leakage," where hidden model preferences are exposed through log-probability analysis. This work highlights the importance of using frameworks like MENAValues to assess the cultural sensitivity of LLMs.
                        </p>
                    </div>
                    </div>
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="Cap3ture (3).png" />
                    </div>
                    <div class="project-info">
                        <h3 style="color: #6A5ACD;"><B>Translate With Care: Addressing Gender Bias, Neutrality, and Reasoning in LLM Translations</B> (Findings-ACL 2025)</h3>
                        <h4><span style="text-decoration: underline;">Pardis Sadat Zahraei</span>, Ali Emami</h4>
                        <p>
This paper addresses gender bias and logical coherence in machine translation, particularly between gendered languages like English and genderless ones such as Persian. We introduce the Translate-with-Care (TWC) dataset, which includes 3,950 challenging scenarios to test translation systems. Our findings show that all tested models struggle with genderless content, often defaulting to masculine pronouns in professional contexts. We demonstrate that fine-tuning an open-source model on our dataset can significantly reduce these biases and errors, outperforming proprietary LLMs.
                        </p>
                    </div>
                    </div>
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="imresizer-1730263713072.png" />
                    </div>
                    <div class="project-info">
                        <h3 style="color: #3CB371;"><B>WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts</B> (EACL 2024)</h3>
                        <h4><span style="text-decoration: underline;">Pardis Sadat Zahraei</span>, Ali Emami</h4>
                        <p>
Tree-of-Experts (ToE) is a new prompting method that improves the generation of Winograd Schema Challenge questions, achieving 50% valid cases compared to 10% with existing methods. Using ToE, we created WSC+, a dataset of 3,026 LLM-generated questions that includes new categories for ambiguous and offensive content. Our findings show that while GPT-4 leads LLM performance on WSC+ with 68.7% accuracy, this falls well below human performance of 95.1%. We also found that LLMs don't necessarily answer their own generated questions better than those created by other models.
                        </p>
                        <a href="https://aclanthology.org/2024.eacl-long.99/" target="_blank">View Paper</a> |
                        <a href="https://github.com/pardissz/WSCplus-TreeOfExperts" target="_blank">View GitHub</a> |
                        <a href="https://aclanthology.org/2024.eacl-long.99.mp4" target="_blank">View Video</a>
                    </div>
                    </div>
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="resized_image2.png" />
                    </div>
                    <div class="project-info">
                        <h3 style="color: #BA55D3;"><B>TuringQ: Benchmarking AI Comprehension in Theory of Computation</B> (Findings-EMNLP 2024)</h3>
                        <h4><span style="text-decoration: underline;">Pardis Sadat Zahraei</span>, Ehsaneddin Asgari</h4>
                        <p>
TuringQ is the first benchmark that tests LLMs' reasoning abilities in theoretical computer science. Testing with Chain of Thought prompting on various LLMs, we developed an automated evaluation system that performs similarly to human experts. Fine-tuning Llama3-8B on TuringQ improved both its theoretical reasoning and performance on related tasks like algebra, demonstrating the benchmark's value for advancing LLM capabilities in computational theory.
                        </p>
                        <a href="https://arxiv.org/abs/2410.06547" target="_blank">View Paper</a> |
                        <a href="https://github.com/language-modeling-lab/TuringQ" target="_blank">View GitHub</a> |
                        <a href="https://huggingface.co/datasets/llm-lab/TuringQ" target="_blank">View Dataset</a> |
                        <a href="https://huggingface.co/llm-lab/Llama3-8B-ft-TuringQ" target="_blank">View Model</a>
                    </div>
                    </div>
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="resized_image.png" />
                    </div>
                    <div class="project-info">
                        <h3 style="color: #DAA520;"><B>Detecting Bias and Enhancing Diagnostic Accuracy in Large Language Models for Healthcare</B> </h3>
                        <h4><span style="text-decoration: underline;">Pardis Sadat Zahraei</span>, Zahra Shakeri</h4>
                        <p>
Biased AI medical advice poses risks to patient safety as LLMs increasingly influence healthcare decisions. This study introduces two key resources: BiasMD (6,007 Q&A pairs for bias evaluation) and DiseaseMatcher (32,000 clinical Q&As covering 700 diseases). Using these datasets, we developed EthiClinician, a fine-tuned model that surpasses GPT-4 in ethical reasoning and clinical judgment, setting new standards for safer AI-driven healthcare outcomes.
                        </p>
                        <a href="https://arxiv.org/abs/2410.06566" target="_blank">View Paper</a> |
                        <a href="https://github.com/HIVE-UofT/Detecting-Bias-and-Enhancing-Diagnostic-Accuracy" target="_blank">View GitHub</a> |
                        <a href="https://huggingface.co/datasets/PardisSzah/BiasMD" target="_blank">View BiasMD</a> |
                        <a href="https://huggingface.co/datasets/PardisSzah/DiseaseMatcher" target="_blank">View DiseaseMatcher</a> |
                        <a href="https://huggingface.co/PardisSzah/EthiClinician" target="_blank">View Model</a>
                    </div>
                    </div>
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="CaptuØ±re (1).png" />
                    </div>
                    <div class="project-info">
                        <h3 style="color: #4682B4;"><B>Generative AI for Character Animation: A Comprehensive Survey</B></h3>
                        <h4>Mohammad Mahdi Abootorabi, Omid Ghahroodi, <span style="text-decoration: underline;">Pardis Sadat Zahraei</span>, et al.</h4>
                        <p>
This survey offers a comprehensive overview of how generative AI is applied to character animation, covering facial animation, motion synthesis, and more. It highlights key research, datasets, and trends, providing a single, integrative perspective on the field. The paper also discusses open challenges and future research directions to help researchers and developers advance AI-driven animation technologies.
                        </p>
                    </div>
                    </div>
                </div>
        </div>
    </div>

    <div id="projects" class="background-alt">
        <h2 class="heading">Projects</h2>
        <div class="container">
            <div class="row">
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="imresizer-1730264671838.png" />
                    </div>
                    <div class="project-info">
                        <h3>Persian Ease & Persian Formalizer</h3>
                        <p>
Persian Ease and Persian Formalizer are a pair of complementary language models fine-tuned for Persian text style transfer:

Persian Ease transforms formal Persian text into a more casual, conversational style
Persian Formalizer converts informal Persian text into formal language suitable for professional or academic contexts

Both models leverage fine-tuning techniques to preserve meaning while adapting the linguistic style appropriately.                        </p>
                         <a href="https://huggingface.co/parsi-ai-nlpclass/PersianEase" target="_blank">View PersianEase</a> |
                         <a href="https://huggingface.co/parsi-ai-nlpclass/PersianTextFormalizer" target="_blank">View PersianTextFormalizer</a>
                    </div>
                    </div>
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="imresizer-1730382094806.png" />
                    </div>
                    <div class="project-info">
                        <h3>Persian NER and Text Summarization</h3>
                        <p>
Implemented dual transformer-based models (mT5 and BERT) for Persian language processing, featuring Named Entity Recognition (NER) for token classification and an abstractive text summarization system.            </p>
                        <a href="https://huggingface.co/PardisSzah/Persian_Summarizer_MT5" target="_blank">View PersianSummarizer</a>
                                            |    <a href="https://huggingface.co/PardisSzah/Persian_NER_parsbert" target="_blank">View PersianNER</a>


                    </div>
                    </div>
                <a id="view-more-projects" href="#">View More Projects</a>
<div id="more-projects" class="row">
    <div class="project shadow-large">
        <div class="project-image">
            <img src="imresizer-1730381060654.png" />
        </div>
        <div class="project-info">
            <h3>Cross-Lingual Drug Name Prediction</h3>
            <p>
This project develops a model to accurately predict drug names in both Persian and English using embedding techniques, FastText and BERT. By leveraging these embeddings, the model predicts drug names based on specific features and patterns in the input data. This bilingual approach enables pharmaceutical and healthcare applications to enhance drug name identification and suggestion in multilingual environments.


            </p>
            <a href="https://github.com/pardissz/NLP_HW3">View Project</a>
        </div>
        </div>
    <div class="project shadow-large">
        <div class="project-image">
            <img src="imresizer-1730382021097.png" />
        </div>
        <div class="project-info">
            <h3>Sentiment Analysis on Social Media Data with Custom NLP Pipeline</h3>
            <p>
This project conducts sentiment analysis on Twitter and YouTube data, implementing a specialized preprocessing pipeline to improve accuracy and contextual understanding. The pipeline includes essential NLP steps such as lemmatization, tokenization, NER, and spell checking, along with advanced customizations like bigram verification, contradiction resolution, and a slang dictionary tailored to social media language. These techniques enable more accurate and nuanced sentiment insights by accounting for informal language, abbreviations, and unique social media expressions.
            </p>
            <a href="https://github.com/pardissz/NLP_HW3">View Project</a>
        </div>
        </div>
    </div>

            </div>
        </div>
    </div>
    <div id="contact" style="color: white;">
    <h2>Contact</h2>
    <p>
        I'm always open to conversations and potential collaborations! Feel free to reach out at
        <a href="mailto:zahraei2@illinois.edu" style="color: white; text-decoration: underline;">
            zahraei2 [at] illinois [dot] edu
        </a>.
    </p>
</div>

    <footer>
        <div class="container">
            <div class="row">

                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>
                <div class="col-sm-5 social">
                    <ul>
                        <li>
                            <a href="https://github.com/pardissz" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://huggingface.co/PardisSzah" target="_blank">ðŸ¤—</a>
                        </li>
                        <li>
                            <a href="https://linkedin.com/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://x.com/PardisZahraei" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
                        </li>

<li>
    <a href="https://scholar.google.com/citations?user=L_9-zNYAAAAJ&hl=en" target="_blank"><i class="fa fa-graduation-cap" ></i></a>
</li>
                    </ul>
                </div>
            </div>
        </div>
    </footer>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.min.js"></script>
</body>

</html>